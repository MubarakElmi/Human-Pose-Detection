{"cells":[{"cell_type":"code","execution_count":null,"id":"381c1f96","metadata":{"id":"381c1f96"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import numpy as np\n","import cv2\n","import  matplotlib.pyplot as plt "]},{"cell_type":"code","execution_count":null,"id":"80cea028","metadata":{"id":"80cea028"},"outputs":[],"source":["# MultiPose Model\n","model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n","movenet = model.signatures['serving_default']"]},{"cell_type":"code","execution_count":null,"id":"6f6236f1","metadata":{"id":"6f6236f1"},"outputs":[],"source":["# SinglePose Model\n","interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n","interpreter.allocate_tensors()"]},{"cell_type":"code","execution_count":null,"id":"621b858d","metadata":{"id":"621b858d"},"outputs":[],"source":["#Anahtar Noktaları Çizmek"]},{"cell_type":"code","execution_count":null,"id":"df1e7112","metadata":{"id":"df1e7112"},"outputs":[],"source":["def draw_keypoints(frame, keypoints, confidence_threshold):\n","    y, x, c = frame.shape\n","    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n","    \n","    for kp in shaped:\n","        ky, kx, kp_conf = kp\n","        if kp_conf > confidence_threshold:\n","            cv2.circle(frame, (int(kx), int(ky)), 6, (0,255,0), -1)\n"," #(int(kx), int(ky)) kullanarak frame üzerinde 6 piksel çapında  bir daire çizer"]},{"cell_type":"code","execution_count":null,"id":"70f1733e","metadata":{"id":"70f1733e"},"outputs":[],"source":["#Bu edegler aslında hangi koordinatın hangi diğer koordinata bağlandığını temsil eder.\n","EDGES = {\n","    (0, 1): 'm',\n","    (0, 2): 'c',\n","    (1, 3): 'm',\n","    (2, 4): 'c',\n","    (0, 5): 'm',\n","    (0, 6): 'c',\n","    (5, 7): 'm',\n","    (7, 9): 'm',\n","    (6, 8): 'c',\n","    (8, 10): 'c',\n","    (5, 6): 'y',\n","    (5, 11): 'm',\n","    (6, 12): 'c',\n","    (11, 12): 'y',\n","    (11, 13): 'm',\n","    (13, 15): 'm',\n","    (12, 14): 'c',\n","    (14, 16): 'c'\n","}"]},{"cell_type":"code","execution_count":null,"id":"358cdb4c","metadata":{"id":"358cdb4c"},"outputs":[],"source":["# Anahtar noktaları_with_scores içinde döner ve her bir kişi için draw_connections ve draw_keypoints fonksiyonlarını çağırarak anahtar noktaları ve kenarları frame üzerinde çizer\n","def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n","    for person in keypoints_with_scores:\n","        draw_connections(frame, person, edges, confidence_threshold)\n","        draw_keypoints(frame, person, confidence_threshold)"]},{"cell_type":"code","execution_count":null,"id":"9b5ca0da","metadata":{"id":"9b5ca0da"},"outputs":[],"source":["def draw_connections(frame, keypoints, edges, confidence_threshold):\n","    y, x, c = frame.shape\n","    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n","    \n","    for edge, color in edges.items():\n","        p1, p2 = edge\n","        y1, x1, c1 = shaped[p1]\n","        y2, x2, c2 = shaped[p2]\n","        \n","        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n","            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255,0,0), 4)\n","\n","  #np.squeeze anahtar dizisini çıkarmayı kolaylaştırın\n","  #  Her iki anahtar noktasının güven seviyesi güven seviyesi eşiğinden yüksekse, anahtar noktaların koordinatlarını\n"," #(int(x1), int(y1)) ve (int(x2), int(y2)) kullanarak frame üzerinde mavi renkte bir çizgi çizer. "]},{"cell_type":"markdown","source":["# SinglePose "],"metadata":{"id":"3H9N1qo64KK9"},"id":"3H9N1qo64KK9"},{"cell_type":"code","execution_count":null,"id":"0e1f3fdb","metadata":{"id":"0e1f3fdb"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    \n","     # Görüntüyü yeniden boyutlandırmak\n","    img = frame.copy()\n","    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n","    input_image = tf.cast(img, dtype=tf.float32)\n","    \n","    # Kurulum girişi ve çıkışı\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","    \n","    # görüntünün anahtar noktalarını tahmin etme işlemi gerçekleştirir.\n","    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n","    interpreter.invoke()\n","    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n","    \n","    # Anahtar noktaları oluşturma  \n","    draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n","    draw_keypoints(frame, keypoints_with_scores, 0.4)\n","    \n","    cv2.imshow('MoveNet Lightning', frame)\n","    \n","    if cv2.waitKey(10) & 0xFF==ord('e'):\n","        break\n","        \n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","source":["# MultiPose"],"metadata":{"id":"Gla8BB4w4Qbl"},"id":"Gla8BB4w4Qbl"},{"cell_type":"code","execution_count":null,"id":"3af10e2e","metadata":{"id":"3af10e2e"},"outputs":[],"source":["\n","\n","people_count = 0\n","\n","cap = cv2.VideoCapture(\"dance2.mp4\")\n","\n","while cap.isOpened():\n","    ret,frame = cap.read()\n","    \n","    # Görüntüyü yeniden boyutlandırmak\n","    img = frame.copy()\n","    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 352,640) \n","    input_img = tf.cast(img, dtype=tf.int32)\n","    #WEB KAMERAMIZDAN ALDIĞIMIZ HER BİR FRAME DÖNGÜ İÇİNDE ALIYORUZ\n","    \n","    #Detection section\n","    results = movenet(input_img)\n","    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n","    # Anahtar noktaları oluşturma \n","    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3)\n","        # Ekranda insanlar var mı kontrol et.\n","    confidence_threshold = 0.1\n","    num_people = 0\n","    for person in keypoints_with_scores:\n","        if person[0][2] > confidence_threshold:\n","            num_people += 1\n","    if num_people == 0:\n","        people_count = 0\n","    elif num_people > people_count:\n","        people_count = num_people\n","    cv2.putText(frame, f\"People: {people_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","    \n","    \n","    \n","    cv2.imshow(\"Movenet Multipose\", frame)\n","\n","    if cv2.waitKey(10) & 0xFF==ord(\"e\"):\n","        break\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"id":"bf1d2f00","metadata":{"id":"bf1d2f00"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}